[
  {
    "objectID": "portfolio/index.html#control-vs-design-regulatory-detailed-planning-2010",
    "href": "portfolio/index.html#control-vs-design-regulatory-detailed-planning-2010",
    "title": "Portfolio",
    "section": "Control vs Design | Regulatory Detailed Planning (2010)",
    "text": "Control vs Design | Regulatory Detailed Planning (2010)"
  },
  {
    "objectID": "portfolio/index.html#skin-green-bud-2011",
    "href": "portfolio/index.html#skin-green-bud-2011",
    "title": "Portfolio",
    "section": "Skin | Green Bud (2011)",
    "text": "Skin | Green Bud (2011)"
  },
  {
    "objectID": "portfolio/index.html#joints-growing-structure-2008",
    "href": "portfolio/index.html#joints-growing-structure-2008",
    "title": "Portfolio",
    "section": "Joints | Growing Structure (2008)",
    "text": "Joints | Growing Structure (2008)"
  },
  {
    "objectID": "portfolio/index.html#uniformity-variety-budget-hotel-2008",
    "href": "portfolio/index.html#uniformity-variety-budget-hotel-2008",
    "title": "Portfolio",
    "section": "Uniformity & Variety | Budget Hotel (2008)",
    "text": "Uniformity & Variety | Budget Hotel (2008)"
  },
  {
    "objectID": "portfolio/index.html#cells-x-functions-commnunity-center-2009",
    "href": "portfolio/index.html#cells-x-functions-commnunity-center-2009",
    "title": "Portfolio",
    "section": "Cells x Functions | Commnunity Center (2009)",
    "text": "Cells x Functions | Commnunity Center (2009)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Liu Liu",
    "section": "",
    "text": "I am a Ph.D. candidate at MIT studying Computational Urban Science, and working at City Form Lab. Being a scientist with eight years of entrepreneurship in data-driven urban analytics and six years of design training, I focused on the built environment and human behavior analysis by adopting computer vision.\nBefore returning to MIT, I am the founder of CitoryTech Co LTD (城室科技), a start-up in urban computation specializing in urban visual AI. Besides, I was an external expert for Tencent, a consultant for the World Bank, and an urban researcher at the China Academy of Urban Planning and Design. I am currently working as an Applied Scientist PhD Intern at Amazon, collaborating with the AGI Foundation.\nMy academic interests lie in the interdisciplinary fields of AI, machine learning, optimization, and urban design research."
  },
  {
    "objectID": "projects/riverview/index.html",
    "href": "projects/riverview/index.html",
    "title": "River View Analysis",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nTo preserve the natural landscapes along the Qiantang River, I analyzed a 200-kilometer stretch of riverbank videos. By carefully examining the footage, I calculated the visual proportions of seven distinct elements present throughout the entire shoreline. Subsequently, I developed a visualization platform that identifies and maps these elements along the riverbank. This platform is a valuable tool in safeguarding the natural beauty and ecological integrity of the Qiantang River, enabling effective management and conservation efforts.\nThis work has been re-presented in Rez de Ville / Urban Ground Floors 2023.\n\n\n\nThe Idea\n\nThis project aims to protect the historical and cultural features of the Qiantang River and the upstream Fuchun River and Xin’an River, covering a more than 200-kilometer waterfront. The famous Fuchun Mountain Habitat map depicts the natural scenery on both sides of the strait, but now it has been damaged by the excessive development of many residential buildings.\n\n\n\nData Process\n\nThe project is conducted based on the video along the Qiantang River, where over 40000 frames are extracted along the three sections covering the north and south bank.\n\nAfter segmenting the video frames into different segmentations, we could view different landscape prototypes along the river.\n\n\n\nResult Analysis\n\nOne of the major triggers for this project is to identify over-developed real estate. By composing metrics such as building height / plant height, it is easily to locate those banks.\n\nOther methods are also applied for each section of the entire river.\n\n\n\nDemo Video\n\nBelow is a platform we created for verifying the metrics for different waterfront view sections."
  },
  {
    "objectID": "projects/huipai/index.html",
    "href": "projects/huipai/index.html",
    "title": "AI-Aided Camera App",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nThis app integrates deep models to learn the operation and mode of photo shooting from the massive works of professional photographers and realizes the comprehensive scoring of the subject, composition, color, depth of field, exposure, and other angles of the picture. It can automatically extract the current scene’s geometric structure and professional characteristics and give improvement tips for composition. A live demo was recorded on 2020 Apr 30 in Shanghai with Huawei Mate 30.\nThis project was terminated during the decrease of tourism in 2020. It’s an independent project and the business plan can be viewed here. To obtain the password to view the BP, please contact me.\n\n\n\nThe Idea\n\nThe foundational idea behind developing this tool is to “help beginners transform into photography experts.” Based on the scene in view, it automatically offers users specific photography suggestions and provides “photography composition guidelines.”\n\n\n\nFunction 1: Composition Recognization\n\nThe tool analyzes the current camera frame, identifies the composition structure, and recommends suitable composition schemes. It can automatically identify 12 major categories and 34 subcategories of compositional benchmarks.\n\n\nThere are two ways of giving users hints about the composition. First, we plot the guidelines on the pictures directly:\n\n\n\nSecond, we provide typical photos with similar compositions:\n\n\n\n\n\nFunction 2: Suggestions based on Scenes\n\nIn addition to this, it can also recognize shooting scenes from 26 major categories and over 100 subcategories. For example, it can identify the current shooting scene and subject, then propose photography suggestions for optimizing the photo. By recognizing the content of the day’s photography subject, it can analyze and understand the content of the subject being shot. Furthermore, it can identify the current pose structure (standing, sitting, etc.) of the person being photographed.\n\n\n\n\nDemo Video\n\nBelow is a demo video we recorded based on Huawei Mate 30 in April, 2020."
  },
  {
    "objectID": "projects/lbsn/index.html",
    "href": "projects/lbsn/index.html",
    "title": "1 Billion LBSN Data",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nBoth figures show the average daily population flow distribution among more than 2,000 county-level units. The picture on the left is the average for workdays, and the picture on the right reflects the weekend situation. The former has a “diamond structure” dominated by the Beijing-Tianjin-Hebei, Yangtze River Delta, Pearl River Delta, Chengdu-Chongqing, and Mid-Delta metropolitan areas. The density of the latter reflects the strength of travel in various regions.\n\nHongMou Zhang, Liu Liu, Pensen Wang, Jinhua Zhao, “Depicting the Blurred Regional Boundaries in China Using Individual Mobility Data”\n\nThis work has been presented in China Urban Planning Annual Conference 2016.\n\n\n\nThe Idea\n\nAccording to the closeness of the connection, more than 2,000 county-level units are drawn into a pattern with a gravity layout. Through community detection, about 20 clusters are highlighted, and many share typical degrees of development. For example, most provincial capital cities belong to a single-center model, while the Yangtze and Pearl River Delta metropolitan areas present a network structure.\nThe Following Articles are translated from Chinese versions: City Clusters and City Flows.\n\n\n\nData Source\n\nTencent’s big data research has achieved the highest level in national-scale spatial research, with 600 million monthly active users. They conducted extensive research using large-scale sampling over a wide range of time and space. Utilizing the Tencent Cloud team’s data foundation and technical expertise, they focused on various topics such as migration patterns from Beijing, Shanghai, and Guangzhou, travel analysis during the Spring Festival, tourism trends on National Day, and early urban congestion warnings. To explore more about Tencent LBSN research, follow their official account, “Yi Chu Xing,” or check out the “WeChat-Wallet-City Service-City Heat Map” for area-specific heat maps.\nThis unprecedented collaboration between the two parties involved a customized cooperation plan to align their needs and ensure smooth research development. The study incorporated three types of research data: population distribution in 10-square-kilometer grid units across the country, population flow matrix across 2,242 county-level units, and message flow within the same county-level units. To ensure comprehensive analysis, the research spanned four distinct periods: five working days, weekends, National Day, and Spring Festival. (For clarification, “population” refers to the research subject below.)\n\n\n\nDistribution of National Population\n\nThe number of active Tencent users shows a strong correlation (correlation coefficient of 0.91) with the user count of 1.33 billion people in China’s Sixth Census, based on the division of county-level units.\nAnalyzing the user distribution on a city scale reveals a polarized pattern within Tencent’s system. In major cities with populations of 1 million or even 10 million, according to the Sixth Census, the concentration of Tencent users surpasses the statistical population. Similarly, unit areas with populations below 500,000 also have relatively high numbers of Tencent users. For ease of comparison, the coordinates in the figure are approximately scaled at a 1:2 ratio.\nApart from comparing census data, the 2014 national and provincial resident population statistics can also be utilized for provincial-level comparisons. In most provinces, the proportional relationship between the two datasets remains close to 1:2.\nInterestingly, when mapping the data spatially, provinces and cities with a higher proportion of Tencent users form a distinctive “ring” pattern. We propose a possible explanation for provinces and cities with lower proportions: the underdeveloped regions in the central and western areas, divided by the Hu Huanyong line, may have insufficient sample sizes of sparsely populated users. As a result, the two circled areas in Northeast China and Central China may more accurately reflect population loss. In other words, these areas might have a significant number of registered populations, but a large portion of them have relocated, and based on location point calculations, they are not considered current residents.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation Flows\n\n\n\n\nCity Clusters\n\nThere are numerous definitions of urban agglomeration, and opinions among academics also vary. This article refrains from delving into extensive analysis or explanations. The following map, resembling a “nebula,” disregards the geographical locations of individual units. Instead, units are positioned closer to each other based on the strength of population flow connections, following the gravity model. (Gephi offers various layouts, and this is just one of them.) To ensure clarity, it is more suitable to use the term “urban community” rather than urban agglomeration to describe the research subject. Notably, the most prominent clusters, akin to dazzling stars in the night sky, primarily consist of renowned urban agglomerations and regions, such as Beijing-Tianjin-Hebei, Yangtze River Delta, Pearl River Delta, Chengdu-Chongqing, and more. Provincial capital cities, including Taiyuan, Xi’an, and Changsha lead the secondary star clusters.\n\nThere are also some particular star-like clusters, such as the one in Shandong Province, probably due to the mountain landscape.\n\nWhen projecting the distribution of these nebulae back into spatial positions, a completely different pattern emerges. By counting, we can identify 17 “urban associations.” Overall, these associations exhibit a spatial clustering pattern. However, unlike previous divisions of related urban agglomerations, most of these “urban associations” feature “breaks” or “enclaves.” This outcome is a result of not intentionally considering spatial adjacency constraints during calculations, and it objectively reflects the development imbalances between cities or regions, particularly in terms of population flow strength.\nLet’s take a closer look at the “Yangtze River Delta City Association” as an example. In addition to the conventional analysis that includes southern Jiangsu and northern Zhejiang, it is observed that Xuzhou, Lianyungang, and other cities in northern Jiangsu also have close ties to the association. This reflects the strengthening connection between the southern and northern parts of Jiangsu province, while a certain gap exists in the central area of Jiangsu. Furthermore, within the Yangtze River Delta region, Anhui is identified as another “community” centered around Hefei. This suggests that, based on existing population contact data, Anhui has not yet formed close connections with the developed regions of the Yangtze River Delta. Indeed, many “communities” align with provincial boundaries, adhering to the administrative management system in China. However, there are exceptions to this pattern. For instance, the “Pearl River Delta Urban Associations” extend their influence to Jiangxi, Hunan, Guangxi, and other neighboring areas beyond Guangdong Province. Furthermore, cities like Harbin in Heilongjiang, located far away, bypass the “Liaoshen urban community” and establish direct connections with Beijing, Tianjin, and Hebei. These exceptions highlight the complex dynamics of urban interactions that sometimes transcend administrative boundaries. In addition to utilizing data from working days for division, other time periods can also be employed for the same analysis. For instance, the provided image demonstrates a division based on the National Day period. In addition to employing the community detection model, another approach to analyze connections is through the use of K-Core. This method is generally associated with determining the prominence of a city. The higher the connectivity of a city or region, the higher its K-Core value, indicating its elevated status."
  },
  {
    "objectID": "projects/road/index.html",
    "href": "projects/road/index.html",
    "title": "Road Assessment in Ulaanbaatar",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nThe condition of transportation assets can be effectively observed through user-generated content (UGC) images. Analyzing geo-tagged images makes it possible to link the condition reflected in the images to specific geographic locations. This approach has been employed for various transportation assets such as catch basins, guardrails, manholes, road curbs, road markings, road signs, roadways, and sidewalks. By associating these images with corresponding road segments, a comprehensive understanding of the condition of these assets can be generated. This enables better asset management and maintenance strategies, ultimately contributing to safer and more efficient transportation systems.\n\nZhang, D., Yi, H., Chen, Y., Jiang, N., Shao, J., & Liu, L. “An urban infrastructure assessment system built on geo-tagged images and machine learning” Computational Urban Science.\n\n\n\n\nThe Idea\n\nThe labeled images would be used as training data sets. According to their Q score, a process of ‘classification-then-regression’ would be conducted. Deep learning models would be built to extract deep features of the labeled images with transportation assets in different conditions.\n\n\n\nDemo Video\n\nBelow is a brief demo of our platform for the visualization of the analytic results."
  },
  {
    "objectID": "projects/cityeye/index.html",
    "href": "projects/cityeye/index.html",
    "title": "CityEye WeChat mini APP",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nCityEye is a WeChat mini application specifically designed for group field trips. Currently, it caters to a user base of over 10,000 individuals, primarily consisting of design background students and planners. This innovative urban photo survey tool integrates various functionalities, including image collection, recognition, and data analysis. By combining these features, CityEye facilitates the efficient gathering of urban data, enabling users to analyze and interpret the collected images for their research or planning purposes.\nAfter 3 years of running, we accumulated over 5000 users globally. Yet unfortunately, the tool is currently shutdown due to a lack of budget. We will relaunch it if having enough funding in the future, and please feel free to contact me.\n\n\n\nThe Idea\n\n\n\n\nThe Function of the APP"
  },
  {
    "objectID": "visualization/index.html",
    "href": "visualization/index.html",
    "title": "Visualization",
    "section": "",
    "text": "TIP\n\n\n\nTo obtain the slides view password, please contact me."
  },
  {
    "objectID": "visualization/index.html#urban-growth-2020",
    "href": "visualization/index.html#urban-growth-2020",
    "title": "Visualization",
    "section": "Urban Growth (2020)",
    "text": "Urban Growth (2020)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nIn this project, we provided a well-known real estate developer with an assessment of the development overview and future evolution of China’s five major city clusters. This study combined the LandScan population change data over the past 20 years with the scope of urban land boundaries inferred from VIIRS data, conducting a comprehensive and large-scale comparison over a long period between “people” and the spatial expansion of “cities.”\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "visualization/index.html#aesthetic-evaluation-2019",
    "href": "visualization/index.html#aesthetic-evaluation-2019",
    "title": "Visualization",
    "section": "Aesthetic Evaluation (2019)",
    "text": "Aesthetic Evaluation (2019)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nAdopting an approach similar to Place Pulse, we developed a tool for our government clients that integrates calibration scoring, assessment, and the automatic training and generation of recommended signage for stores."
  },
  {
    "objectID": "visualization/index.html#vge-for-lujiazui-2019",
    "href": "visualization/index.html#vge-for-lujiazui-2019",
    "title": "Visualization",
    "section": "VGE for Lujiazui (2019)",
    "text": "VGE for Lujiazui (2019)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nIn this project, we utilized Unreal Engine 4 (UE4) to reconstruct a game-like virtual space for the Lujiazui District in Shanghai. The project designed a skywalk, connecting the various buildings of this prime commercial center in the heart of Shanghai. This connection enhanced the environment and reshaped the public space, elevating the overall experience of the area."
  },
  {
    "objectID": "visualization/index.html#hour-of-jialing-river-2018",
    "href": "visualization/index.html#hour-of-jialing-river-2018",
    "title": "Visualization",
    "section": "24 Hour of Jialing River (2018)",
    "text": "24 Hour of Jialing River (2018)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nIn this project, based on the 24-hour China Unicom mobile signaling data of Chongqing, we analyzed the population mobility data along the banks of the Jialing River. From this analysis, we identified the movement patterns of different types of populations.\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "visualization/index.html#time-contour-2018",
    "href": "visualization/index.html#time-contour-2018",
    "title": "Visualization",
    "section": "Time contour (2018)",
    "text": "Time contour (2018)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nIn this project, we built a web-app based on Didi driving speed data to retrieve the time contour of any point in Shanghai based on different period of a day. One of the original idea of this project is to find the “meeting point” for users within the same city after work."
  },
  {
    "objectID": "visualization/index.html#visual-comfortness-2018",
    "href": "visualization/index.html#visual-comfortness-2018",
    "title": "Visualization",
    "section": "Visual Comfortness (2018)",
    "text": "Visual Comfortness (2018)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nThis project involves a study on street environment comfort assessment conducted in a community in Nanjing. We collected videos of the walking environment throughout the community and conducted a comprehensive assessment using computer vision, including object detection, semantic segmentation, and more.\nLater on, a similar approach was carried out for a TOD study in Beijing in collaboration with World Bank. The report can be view here.\n\n\n\n\n\nReport Here"
  },
  {
    "objectID": "visualization/index.html#hour-cycling-2017",
    "href": "visualization/index.html#hour-cycling-2017",
    "title": "Visualization",
    "section": "24 Hour Cycling (2017)",
    "text": "24 Hour Cycling (2017)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nThis a visualization demo based on user data from Xingzhe shown on the 2017 Bicycle EXPO."
  },
  {
    "objectID": "visualization/index.html#ai-book-2017",
    "href": "visualization/index.html#ai-book-2017",
    "title": "Visualization",
    "section": "AI Book (2017)",
    "text": "AI Book (2017)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nThis is a user interaction screen provided inside a popular bookstore designed by Tadao Ando.\n\n\n\n\n\nMedia Exposure"
  },
  {
    "objectID": "visualization/index.html#patterns-finder-2017",
    "href": "visualization/index.html#patterns-finder-2017",
    "title": "Visualization",
    "section": "Patterns Finder (2017)",
    "text": "Patterns Finder (2017)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nA working-on projects for any user who draws some lines to provide best matched satellite images all over the world."
  },
  {
    "objectID": "visualization/index.html#informal-vendors-2016",
    "href": "visualization/index.html#informal-vendors-2016",
    "title": "Visualization",
    "section": "Informal Vendors (2016)",
    "text": "Informal Vendors (2016)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nWe extracted features from urban street scenes using a trained model and then further identified the vaguely defined content of “informal street vendors” through additional manual calibration. Applying fine-tuning to this specific scenario in urban research was an innovation at the time."
  },
  {
    "objectID": "visualization/index.html#shenzen-pulse-2014",
    "href": "visualization/index.html#shenzen-pulse-2014",
    "title": "Visualization",
    "section": "Shenzen Pulse (2014)",
    "text": "Shenzen Pulse (2014)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nWe collected a vast amount of check-in data from Weibo and used it to visualize the evolution of maps based on 24-hour periods."
  },
  {
    "objectID": "visualization/index.html#boston-taxi-2013",
    "href": "visualization/index.html#boston-taxi-2013",
    "title": "Visualization",
    "section": "Boston Taxi (2013)",
    "text": "Boston Taxi (2013)\n\n\n\n\n\n\n\n\nINFO\n\n\n\nThis is the visualization work based a Boston Taxi data challenge."
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Research papers",
    "section": "",
    "text": "Liu, L., Marco Cipriano, Freya Tan, Alexandra Kudaeva, Andres Sevtsuk, & Gerard de Melo\nObserving the “Sidewalk Ballet”: Leveraging LLMs to Detect Social Interactions in Street-View Images\nCUPUM 2025 – Computational Urban Planning & Urban Management, London, UK.\nView\nHosseini, M., Cipriano, M., Eslami, S., Hodczak, D., Liu, L., Sevtsuk, A., & de Melo, G.\nELSA: Evaluating Localization of Social Activities in Urban Streets\narXiv preprint arXiv:2406.01551 (2024).\nDownload\nLiu, L., & Andres Sevtsuk\nClarity or Confusion: A Review of Computer-Vision Street Attributes in Urban Studies and Planning\nCities, 150, 105022 (2024).\nView\nColaninno, N., Rounaq Basu, Maryam Hosseini, Abdulaziz Alhassan, Liu Liu, & Andres Sevtsuk\nA Sidewalk-Level Urban Heat-Risk Assessment Framework Using Pedestrian Mobility and Urban Micro-climate Modelling\nEnvironment & Planning B: Urban Analytics and City Science (2024).\nView\nZhou, B., Liu, L., Oliva, A., & Torralba, A.\nRecognizing City Identity via Attribute Analysis of Geo-Tagged Images\nEuropean Conference on Computer Vision (ECCV 2014), pp. 519-534.\nDownload\nLiu, L., Zhou, B., Zhao, J., & Ryan, B. D.\nC-IMAGE: City Cognitive Mapping through Geo-Tagged Photos\nGeoJournal, 81 (6), 817-861 (2016).\nView\nLong, Y., & Liu, L.\nHow Green Are the Streets? An Analysis for Central Areas of Chinese Cities Using Tencent Street View\nPLOS ONE, 12 (2), e0171110 (2017).\nDownload\nZhang, F., Zhou, B., Liu, L., Liu, Y., Fung, H. H., Lin, H., & Carlo Ratti\nMeasuring Human Perceptions of a Large-Scale Urban Region Using Machine Learning\nLandscape and Urban Planning, 180, 148-160 (2018).\nView\nLiu, L., Zhang, F., Zhou, B., Wang, Z., & Li, Y.\nSTREETALK: A Navigation System for Pedestrians and Cyclists\nLandscape Architecture Frontiers (2018).\nDownload\nCui, C., et al.\nThe Spatial-Temporal Dynamics of Daily Inter-City Mobility in the Yangtze River Delta: An Analysis Using Big Data\nHabitat International (2020).\nView\nZhang, D., Yi, H., Chen, Y., Jiang, N., Shao, J., & Liu, L.\nAn Urban Infrastructure Assessment System Built on Geo-Tagged Images and Machine Learning\nComputational Urban Science 2 (1), 1-21 (2022).\nDownload\n\n(Additional Chinese-language papers are listed in the PDF CV.)\n\n\n\n\n\nLiu, L., Kudaeva, A., Cipriano, M., Al Ghannam, F., Tan, F., de Melo, G., & Sevtsuk, A.\nMINGLE: VLMs for Semantically Complex Region Detection\nSubmitted to AAAI 2026 – Artificial Intelligence for Social Impact Track, under review.\nSevtsuk, A., Basu, R., Liu, L., Alhassan, A., & Kollar, J.\nNYC Walks: A City-Wide Foot-Traffic Model to Guide Pedestrian-Oriented Planning and Design\nSubmitted to TRB Annual Meeting 2026, under review (Manuscript ID TRBAM-26-00393).\nKang, Y., Chen, J., Liu, L., Sharma, K., Mazzarello, M., Mora, S., Duarte, F.* (corresp.), & Ratti, C.\nHuman vs. AI Safety Perception? Decoding Human Safety Perception with Eye-Tracking Systems, Street-View Images, and Explainable AI\nComputers, Environment & Urban Systems, major revision invited (Manuscript ID CEUS-D-25-00395).\nZhang, H., Liu, L., Wang, P., & Zhao, J.\nDepicting the Blurred Regional Boundaries in China Using Individual Mobility Data\nComputational Urban Science, under review (Manuscript ID CUSC-D-25-00097).\n\n\n\n\n\n\nLiu, L., Gao, X., Gao, Q., & Piramuthu, R.\nABCxM: A Benchmark for Multimodal Models Playing Scores to Music\nCompleted during Applied Scientist PhD Internship, Amazon AGI, Sunnyvale CA (2024).\nDeveloped the first end-to-end benchmark and evaluation framework for notation-to-music generation.\nView upon request\nLiu, L., Gao, X., Gao, Q., & Piramuthu, R.\nVIS: A Benchmark for Foley Models and Visually Indicative Sounds\nCompleted during Applied Scientist PhD Internship, Amazon AGI, Sunnyvale CA (2024).\nCreated human-annotated, multi-domain datasets for evaluating video-to-audio generation models.\nView upon request\n\n\n\n\n\n\nReviewer for Cities, Nature Cities, Sustainable Cities & Society, Environment & Planning B, Journal of Transport & Land Use, Computational Urban Science, and others (20 + reviews).\n\nPrincipal Investigator, “Observing the ‘Sidewalk Ballet’: Leveraging LMMs to Detect Social Interactions in Large-Scale Urban Imagery Datasets,” ACCESS CIS250088 (2025-2026)."
  },
  {
    "objectID": "papers/index.html#peer-reviewed-papers",
    "href": "papers/index.html#peer-reviewed-papers",
    "title": "Research papers",
    "section": "",
    "text": "Liu, L., Marco Cipriano, Freya Tan, Alexandra Kudaeva, Andres Sevtsuk, & Gerard de Melo\nObserving the “Sidewalk Ballet”: Leveraging LLMs to Detect Social Interactions in Street-View Images\nCUPUM 2025 – Computational Urban Planning & Urban Management, London, UK.\nView\nHosseini, M., Cipriano, M., Eslami, S., Hodczak, D., Liu, L., Sevtsuk, A., & de Melo, G.\nELSA: Evaluating Localization of Social Activities in Urban Streets\narXiv preprint arXiv:2406.01551 (2024).\nDownload\nLiu, L., & Andres Sevtsuk\nClarity or Confusion: A Review of Computer-Vision Street Attributes in Urban Studies and Planning\nCities, 150, 105022 (2024).\nView\nColaninno, N., Rounaq Basu, Maryam Hosseini, Abdulaziz Alhassan, Liu Liu, & Andres Sevtsuk\nA Sidewalk-Level Urban Heat-Risk Assessment Framework Using Pedestrian Mobility and Urban Micro-climate Modelling\nEnvironment & Planning B: Urban Analytics and City Science (2024).\nView\nZhou, B., Liu, L., Oliva, A., & Torralba, A.\nRecognizing City Identity via Attribute Analysis of Geo-Tagged Images\nEuropean Conference on Computer Vision (ECCV 2014), pp. 519-534.\nDownload\nLiu, L., Zhou, B., Zhao, J., & Ryan, B. D.\nC-IMAGE: City Cognitive Mapping through Geo-Tagged Photos\nGeoJournal, 81 (6), 817-861 (2016).\nView\nLong, Y., & Liu, L.\nHow Green Are the Streets? An Analysis for Central Areas of Chinese Cities Using Tencent Street View\nPLOS ONE, 12 (2), e0171110 (2017).\nDownload\nZhang, F., Zhou, B., Liu, L., Liu, Y., Fung, H. H., Lin, H., & Carlo Ratti\nMeasuring Human Perceptions of a Large-Scale Urban Region Using Machine Learning\nLandscape and Urban Planning, 180, 148-160 (2018).\nView\nLiu, L., Zhang, F., Zhou, B., Wang, Z., & Li, Y.\nSTREETALK: A Navigation System for Pedestrians and Cyclists\nLandscape Architecture Frontiers (2018).\nDownload\nCui, C., et al.\nThe Spatial-Temporal Dynamics of Daily Inter-City Mobility in the Yangtze River Delta: An Analysis Using Big Data\nHabitat International (2020).\nView\nZhang, D., Yi, H., Chen, Y., Jiang, N., Shao, J., & Liu, L.\nAn Urban Infrastructure Assessment System Built on Geo-Tagged Images and Machine Learning\nComputational Urban Science 2 (1), 1-21 (2022).\nDownload\n\n(Additional Chinese-language papers are listed in the PDF CV.)"
  },
  {
    "objectID": "papers/index.html#papers-under-review",
    "href": "papers/index.html#papers-under-review",
    "title": "Research papers",
    "section": "",
    "text": "Liu, L., Kudaeva, A., Cipriano, M., Al Ghannam, F., Tan, F., de Melo, G., & Sevtsuk, A.\nMINGLE: VLMs for Semantically Complex Region Detection\nSubmitted to AAAI 2026 – Artificial Intelligence for Social Impact Track, under review.\nSevtsuk, A., Basu, R., Liu, L., Alhassan, A., & Kollar, J.\nNYC Walks: A City-Wide Foot-Traffic Model to Guide Pedestrian-Oriented Planning and Design\nSubmitted to TRB Annual Meeting 2026, under review (Manuscript ID TRBAM-26-00393).\nKang, Y., Chen, J., Liu, L., Sharma, K., Mazzarello, M., Mora, S., Duarte, F.* (corresp.), & Ratti, C.\nHuman vs. AI Safety Perception? Decoding Human Safety Perception with Eye-Tracking Systems, Street-View Images, and Explainable AI\nComputers, Environment & Urban Systems, major revision invited (Manuscript ID CEUS-D-25-00395).\nZhang, H., Liu, L., Wang, P., & Zhao, J.\nDepicting the Blurred Regional Boundaries in China Using Individual Mobility Data\nComputational Urban Science, under review (Manuscript ID CUSC-D-25-00097)."
  },
  {
    "objectID": "papers/index.html#manuscripts-completed-not-submitted",
    "href": "papers/index.html#manuscripts-completed-not-submitted",
    "title": "Research papers",
    "section": "",
    "text": "Liu, L., Gao, X., Gao, Q., & Piramuthu, R.\nABCxM: A Benchmark for Multimodal Models Playing Scores to Music\nCompleted during Applied Scientist PhD Internship, Amazon AGI, Sunnyvale CA (2024).\nDeveloped the first end-to-end benchmark and evaluation framework for notation-to-music generation.\nView upon request\nLiu, L., Gao, X., Gao, Q., & Piramuthu, R.\nVIS: A Benchmark for Foley Models and Visually Indicative Sounds\nCompleted during Applied Scientist PhD Internship, Amazon AGI, Sunnyvale CA (2024).\nCreated human-annotated, multi-domain datasets for evaluating video-to-audio generation models.\nView upon request"
  },
  {
    "objectID": "papers/index.html#service-grants",
    "href": "papers/index.html#service-grants",
    "title": "Research papers",
    "section": "",
    "text": "Reviewer for Cities, Nature Cities, Sustainable Cities & Society, Environment & Planning B, Journal of Transport & Land Use, Computational Urban Science, and others (20 + reviews).\n\nPrincipal Investigator, “Observing the ‘Sidewalk Ballet’: Leveraging LMMs to Detect Social Interactions in Large-Scale Urban Imagery Datasets,” ACCESS CIS250088 (2025-2026)."
  },
  {
    "objectID": "projects/caz/index.html",
    "href": "projects/caz/index.html",
    "title": "Recognizing Central Activity Zones",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nUtilizing the concept of entropy, the project aims to quantify the level of functional diversity within different areas of the city. By leveraging a dataset consisting of 300,000 points of interest (POI) from Dianping and office and residential POI data from Anjuke, the project assigns weights to these locations based on their respective scores. These scores indicate the areas with the highest spatial composition within the city. Typically, these dynamic places are considered the most vibrant and active within the urban landscape, reflecting a high degree of functional compounding.\n\nLiu L., Liu Z. “The Recognition of CAZ in Shanghai Based on Evaluated POI.” In: Shen Z., Li M. (eds) Big Data Support of Urban Planning and Management, Advances in Geographic Information Science. Springer, Cham.\n\n\n\n\nThe Idea\n\nUtilizing the concept of entropy, the project aims to quantify the level of functional diversity within different areas of the city. By leveraging a dataset consisting of 300,000 points of interest (POI) from Dianping and office and residential POI data from Anjuke, the project assigns weights to these locations based on their respective scores. These scores indicate the areas with the highest spatial composition within the city. Typically, these dynamic places are considered the most vibrant and active within the urban landscape, reflecting a high degree of functional compounding.\n\n\n\nDataset\n\nI utilize a diverse dataset to analyze and identify the Central Activities Zone (CAZ) in Shanghai. This dataset primarily comprises Points of Interest (POI), which include various urban elements like retail outlets, catering services, office spaces, leisure, cultural, and recreational facilities. These POIs are crucial in determining the functional mixture of different urban areas, which in turn helps in recognizing and delineating the CAZ. The dataset’s depth and variety allow for a comprehensive analysis of urban dynamics and the multifunctional nature of Shanghai’s central areas. Updated to August in 2016, this project has captured a total number of 386,628 POI records within the outer ring of downtown Shanghai.\n\n\n\nMethod\n\nThe research method for recognizing Central Activities Zones (CAZ) in Shanghai based on evaluated POI data involves several steps:\nDataset Preparation: Utilizes a dataset of Points of Interest (POI) in Shanghai. The data includes various attributes like shop ID, score, category, and average price.\nCategory Reclassification: Involves regrouping the vast number of POI categories into six general categories: retail, catering, office, recreation, leisure, and culture. This reclassification considers the diversity inherent in CAZs.\nCalibration of Mixture: This step focuses on measuring the degree of functional mixture within areas, which is a key characteristic of CAZs. It involves two dimensions: volume and diversity. The process includes:\nValue Aggregation Map: Normalizing and aggregating heat maps for each category to represent the intensity of functions. Function Intersection Map: Identifying areas with diverse functions by overlaying processed heat maps and classifying places based on the number of overlapping functions. The research aims to identify dynamic and functionally diverse areas in Shanghai that could be recognized as CAZs.\n Value aggregation map of Shanghai (left), the magnified core area (top right)\n Function intersection map of Shanghai (left), and magnified three places: Lujiazui (top), Nanjing Road (middle), Zhongshan Park (bottom)\n The heat map of compiled functions (left) and the contour map of mixture degree (right) and the top 14 mixed-use districts within middle ring of Shanghai\n\n\nFinding the most dynamic areas\n\nThe study identifies the most dynamic areas in Shanghai based on the aggregation and intersection maps created from evaluated POI data. These maps enabled the researchers to determine places with large overall value and multiple functions.\n\nAs for the original target of this project, we demonstrate three possible scenarios for defining the CAZ boundary in Shanghai."
  },
  {
    "objectID": "projects/cimage/index.html",
    "href": "projects/cimage/index.html",
    "title": "C-IMAGE Project",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nThis project originated from my thesis, which involved the collection of millions of photos from 26 cities. The objective was to utilize deep learning techniques to conduct scene recognition on these images. By categorizing the data and plotting the seven critical perceptions, the resulting perceptional maps provide insights into how inhabitants perceive their living environment within each city.\n\nLiu, L., Zhou, B., Zhao, J., & Ryan, B. D. “C-IMAGE: city cognitive mapping through geo-tagged photos” GeoJournal, 81(6), 817-861.\nZhou, B., Liu, L., Oliva, A., & Torralba, A. “Recognizing city identity via attribute analysis of geo-tagged images” European conference on computer vision (pp. 519-534).\n\n\n\n\nInteractive Maps\n\nBelow are interactive maps of the original C-IMAGE cities (recovered from my archive): Amsterdam, Bangkok, Barcelona, Beijing, Hong Kong, Kuala Lumpur, London, New Delhi, New York, Paris, Prague, San Francisco, Seoul, Shanghai, Singapore, Tokyo, Toronto, Vienna, Zurich\n\n\nThe Idea\n\nHalf a century ago, Kevin Lynch’s City Image project provided a collaborative depiction of the “perceived city” by gathering input from the public through a method called “mental mapping.” Now, with the power of computer vision and the ability to leverage crowd-sourced geo-tagged photos, we can explore whether we can detect people’s sentiments towards their physical living environment. By analyzing these images using computer vision algorithms, we aim to gain insights into how individuals feel about their surroundings and further enhance our understanding of urban landscapes.\n\n\n\nData Processing\n\nThe download of the Panoramio geo-tagged images are through Pranoramio data API and Flickr API.\n\n\n\nScene Classification\n\nThe images are classified based on Places 365. For this study, I selected Panoramio and, subsequently, Flickr as the primary sources for data collection. Approximately 30 million photographs were gathered by the completion of the project. The geographical spread of these photos offers a unique perspective, allowing for a comparison with the urban image as conceptualized by Kevin Lynch, which was derived from a multitude of cognitive maps.\n\n\n\nMapping the Perceptions\n\nAfter being processed through scene recognition, currently called Places365, the photos were categorized into 102 attributes. I subsequently conducted a reclassification, streamlining the images to form a generalized portrayal of the city’s public image. This led to retaining only those scenes that are associated with public spaces.\nBy retaining only seven critical perceptions and plotting them on city maps, we can observe varying city patterns that truly reflect what the inhabitants “see.” This approach allows for fascinating discoveries that can be evaluated qualitatively and quantitatively. For instance, a comparison can be made between the perception of green spaces in Shanghai and Tokyo.\n\n\n\nOther Cases\n\nThis method is highly replicable and has been employed in various real-world projects following a relatively fixed procedure. Additionally, the critical perceptions can be broken down into more specific categories. For instance, I divided the green perception into seven sub-elements, which led to discoveries.\n\n\n\nDemo Video\n\nBelow is a demo video showing the distribution of image classification results in Shenzhen."
  },
  {
    "objectID": "projects/streetalk/index.html",
    "href": "projects/streetalk/index.html",
    "title": "StreeTalk Project",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nUsing the perceptional map as a foundation, along with additional geo information such as points of interest (POI) and mobility data, I developed a web application that enables tourists or night runners to select various pedestrian routes within the city. Furthermore, I leveraged the vast dataset of over 100,000,000 photos to calculate safety scores for the entire country. These scores were subsequently sold to Daimler Innovative Lab the following year, providing them with valuable insights and information for their initiatives.\n\nZhang, F., Zhou, B., Liu, L., Liu, Y., Fung, H. H., Lin, H., & Ratti, C. “Measuring human perceptions of a large-scale urban region using machine learning” Landscape and Urban Planning.\nLiu, L., Zhang, F., Zhou, B., Wang, Z., & Li, Y. “STREETALK: A NAVIGATION SYSTEM FOR PEDESTRIANS AND CYCLISTS” Landscape Architecture Frontiers."
  },
  {
    "objectID": "projects/streetalk/index.html#place-pulse-2.0",
    "href": "projects/streetalk/index.html#place-pulse-2.0",
    "title": "StreeTalk Project",
    "section": "Place Pulse 2.0",
    "text": "Place Pulse 2.0\nA significant source of street perception data is the “Place Pulse” project. It collects public feedback on various urban areas using a pairwise labeling interface. Initiated in 2010, the project’s website showcases roughly 4,000 images from four cities: Boston, New York, Linz, and Salzburg. As shown in Figure 1, it gauges public perception across six dimensions. Participants are presented with pairs of street views and asked, “Which image looks safer?”\nOver the years, the dataset was enhanced to version 2.0, which includes 110,998 random street-view images gathered from 56 cities in 28 countries across six continents. From 2013 to 2016, a whopping 81,630 online volunteers took part in the survey, providing over 1,170,000 pairwise comparisons. Given the immense diversity and volume of image samples, participants, and corresponding responses, this dataset closely aligns with general human perceptual preferences regarding urban scenes.\n\n\n\n\nThe top 10 streetview in beautiful Trueskill scores\n\n\n\n\n\nThe bottom 10 streetview in beautiful Trueskill scores"
  },
  {
    "objectID": "projects/streetalk/index.html#binary-svm-for-baseline-measurement",
    "href": "projects/streetalk/index.html#binary-svm-for-baseline-measurement",
    "title": "StreeTalk Project",
    "section": "Binary SVM for Baseline Measurement",
    "text": "Binary SVM for Baseline Measurement\nAs previously discussed, the simplest and most effective method involves training a binary classification model to obtain a predictive model for safety score. Here, we display the accuracy results of binary SVM (Support Vector Machine) for all six models, across six dimensions."
  },
  {
    "objectID": "projects/streetalk/index.html#the-cams-of-street-views",
    "href": "projects/streetalk/index.html#the-cams-of-street-views",
    "title": "StreeTalk Project",
    "section": "The CAMs of street views",
    "text": "The CAMs of street views\nBelow are the negative and positive samples after adopting the updated models.\n\n\n\nThe CAMs of street view with negative safe scores\n\n\n\n\n\nThe CAMs of street view with positive safe scores"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "For more projects, please visit the visualization page.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSidewalk Ballet\n\n\n\ncomputer vision\n\n\nurban design\n\n\n\n\n\n\n\nLiu Liu\n\n\nMay, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVibeScan\n\n\n\ncomputer vision\n\n\nurban design\n\n\npoi\n\n\ntools\n\n\n\n\n\n\n\nLiu Liu\n\n\nFeb, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoad Assessment in Ulaanbaatar\n\n\n\ncomputer vision\n\n\nurban planning\n\n\ntools\n\n\n\n\n\n\n\nLiu Liu, Ding Zhang, Hongdu Yi\n\n\nOct, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Aided Camera App\n\n\n\ncomputer vision\n\n\ntools\n\n\n\n\n\n\n\nLiu Liu, Ding Zhang, Xin Xiong\n\n\nMay, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecognizing Central Activity Zones\n\n\n\nurban planning\n\n\npoi\n\n\nvisualization\n\n\n\n\n\n\n\nLiu Liu, Zhuqing Liu\n\n\nJan, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityEye WeChat mini APP\n\n\n\ncomputer vision\n\n\ntools\n\n\n\n\n\n\n\nLiu Liu, Ding Zhang, Jinxing Shao\n\n\nJan, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRiver View Analysis\n\n\n\ncomputer vision\n\n\nurban design\n\n\n\n\n\n\n\nLiu Liu\n\n\nMay, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStreeTalk Project\n\n\n\ncomputer vision\n\n\nurban design\n\n\n\n\n\n\n\nLiu Liu, Bolei Zhou, Fan Zhang\n\n\nOct, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 Billion LBSN Data\n\n\n\ncellphone data\n\n\nurban planning\n\n\n\n\n\n\n\nLiu Liu, Di An\n\n\nMar, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC-IMAGE Project\n\n\n\ncomputer vision\n\n\nvisualization\n\n\n\n\n\n\n\nLiu Liu, Bolei Zhou\n\n\nMay, 2014\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/sidewalk_ballet/index.html",
    "href": "projects/sidewalk_ballet/index.html",
    "title": "Sidewalk Ballet",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nTraditional urban observational studies rely on direct field observation of public spaces such as sidewalks and plazas to understand how human behaviour and the built environment influence one another. Pioneering scholars, including William H. Whyte, Jan Gehl, and Allan Jacobs, produced influential empirical insights that continue to guide urban design practice. Such work, though invaluable, is labor-intensive, restricted to specific locations, and increasingly challenged by evolving social patterns shaped by digital interaction and algorithmic filter bubbles.\nRecent advances in artificial intelligence, especially computer vision, allow researchers to extract physical indicators from extensive collections of geo‑tagged imagery at an unprecedented scale. Measures such as the Green View Index have become common in urban analytics. However, most applications target the static attributes of the built environment, and very few explore the more intricate realm of human behaviour that earlier manual studies documented.\nMy dissertation proposes a framework that fills this missing piece. I designed an end‑to‑end data collection, processing, and annotation pipeline that fine‑tunes multimodal vision‑language models to recognise the full spectrum of Human Activities and Interactions (HAI) visible in street‑view images. First, the methodological component adapts the models to label combined postures and actions, such as standing, sitting, walking, vending, cycling, using a phone, and over forty additional states, and to detect social groupings (single, dyad, small group, crowd) together with degrees of engagement such as face‑to‑face conversation versus passive co‑presence. The taxonomy is distilled from classic behavioural literature and extensive image inspection. Second, I propose to construct a family of HAI indicators aggregated to uniform sidewalk segments, including Solitary, Grouping, Engagement, Diversity, and Activity Entropy. These indicators are analysed against urban accessibility (pedestrian accessibility and pedestrian flows), design and perceptual attributes (sidewalk width, tree canopy, street‑furniture density, façade transparency, etc.), and socio‑demographic metrics (ethnic composition, age diversity, etc.) from census and mobility data. External comparison with high‑resolution GPS trajectory surveys confirms that segments with higher Activity Entropy or stronger Engagement scores align with observed patterns of pedestrian co‑presence.\n\n\n\nThe City Form Lab exhibit at the 2025 Venice Architecture Biennale showcases two ongoing research projects that examine the geography of foot-traffic and social interactions on the streets of New York: “NYC Walks” and “Sidewalk Ballet”. The exhibit is part of the MIT Department of Architecture led exhibition The Next Earth at the Palazzo Diedo, the exhibition space of Berggruen Arts & Culture.\nHere is the project page link: https://cityform.mit.edu/projects/venice-architecture-biennale-2025"
  },
  {
    "objectID": "projects/vibescan/index.html",
    "href": "projects/vibescan/index.html",
    "title": "VibeScan",
    "section": "",
    "text": "PROJECT BRIEF\n\n\n\nThis project aimed at developing a benchmarking and customer analysis system for commercial areas. Leveraging online feedback, data mining, and AI, it evaluates spaces against industry standards and projects like Miami Design District and Hudson Yards. This approach aids in strategic decision-making across planning, design, and operations, enhancing commercial viability and consumer engagement.\nFor a detailed demonstration of the project, please refer to the slides: Phase I and Phase II.\n\n\n\nThe Idea\n\nIs it possible to gauge public sentiment towards the operational strategies of commercial business sites, particularly in an era where enticing offline shopping has become a paramount challenge for many shopping districts? These areas have significantly invested in enhancing their landscape’s appeal. The question arises: how can we measure the return on investment for these temporary or even permanent enhancements and infrastructure in terms of value to developers? Evaluating the success and failure of space design is crucial. With the wealth of information available on social media platforms, can we harness this publicly accessible data and compile it into a comprehensive public opinion pool? By identifying effective strategies and contrasting them with unsuccessful examples, we can glean insights that are invaluable for future decision-making processes.\n\n\n\nData Process\n\nTons of the data from social media are collected from a wide variety of both China and US social media platform. We usually follows comments and photos from user. For the shopping area cases in Phase I, we mainly collected 14M records (Famous international cases), and 7M in Phase II (Domestic newly built cases).\n\n\n\n\nKey Results\n\n\nAnalysis of Miami District\n\nHot search index of each platform of Miami District.\n\n\n\nBrand check-in rhythm.\n\n\n\nThe investment of leading merchants in space design and the resulting influence of influcers checking in.\n\n\n\n\n\nUsage and comparison of public facilities in the main space.\n\n\n\n\n\n\nAnalysis of Hudson Yards\n\nHot search index of each platform of Miami District.\n\n\n\nPrediction of the structure of the visiting crowd\n\n\n\nThe analysis of social comments on Vessel.\n\n\n\nThe analysis of social comments on Edge.\n\n\n\nThe analysis of social comments on the Shed.\n\n\n\nFor a detailed demonstration of the project, please refer to the slides: Phase I and Phase II."
  },
  {
    "objectID": "presentations/index.html",
    "href": "presentations/index.html",
    "title": "Presentations",
    "section": "",
    "text": "TIP\n\n\n\nTo obtain the slides view password, please contact me."
  },
  {
    "objectID": "presentations/index.html#data-benchmark-for-multi-modality-models",
    "href": "presentations/index.html#data-benchmark-for-multi-modality-models",
    "title": "Presentations",
    "section": "Data Benchmark for Multi-modality models",
    "text": "Data Benchmark for Multi-modality models\n\n\n\n\n\n\n\n\nFinal Presentation @ From Seeing to Hearing\n\n\n\nDate: Aug 22, 2024  Location: Lab 126 Sunnyvale, CA\nThis presentation covers 2 projects I conducted during my research internship at Amazon AGI. They are both related to benchmarks for Audio Generation, in which I highlighted some gaps in today’s AI-driven development. (slides are password protected.)\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#urban-big-data-in-china",
    "href": "presentations/index.html#urban-big-data-in-china",
    "title": "Presentations",
    "section": "Urban Big Data in China",
    "text": "Urban Big Data in China\n\n\n\n\n\n\n\n\nPanel Talk @ 11.001 Intro to Urban Design and Development\n\n\n\nDate: May 8, 2024  Location: 4-370, Massachusetts Institute of Technology\nThis presentation explores my entrepreneurship journey, focusing on urban big data analytics in China. Specifically, I discuss four distinct types of data: open data, web-crawled data, purchased data, and geo-tagged visual data. For each category, I describe 2-3 datasets that I have worked with and detail specific research questions and case studies associated with them.\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#sidewalk-ballet",
    "href": "presentations/index.html#sidewalk-ballet",
    "title": "Presentations",
    "section": "Sidewalk Ballet",
    "text": "Sidewalk Ballet\n\n\n\n\n\n\n\n\nProject Report @ Long Lounge, Building 7, MIT\n\n\n\nDate: Mar 21-22, 2024  Location: School of Architecture and Planning, Massachusetts Institute of Technology\nDuring the SPRING 2024 HPI–MIT WORKSHOP, we delivered the report about current progress in detecting social behaviors on sidewalks. Here is the poster of the project sidewalk ballet. In this project we explored a series of current on-the-shelf models and designed the pipeline of the entire work. More details will be release when our working paper is published, and will be updaed here.\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#learning-from-ground-floors",
    "href": "presentations/index.html#learning-from-ground-floors",
    "title": "Presentations",
    "section": "Learning from ground floors",
    "text": "Learning from ground floors\n\n\n\n\n\n\n\n\nGuest Talk @ Rez de Ville (Urban Ground Floors) 2023\n\n\n\nDate: Sep 22-23, 2023  Location: School of Architecture and Planning, Massachusetts Institute of Technology\nThe 2023 Rez de Ville: In Transition seminar will delve into the evolving dynamics of urban ground floors amidst modern societal, economic, environmental, and technological shifts and explore the implications of these changes on diverse urban populations. Here is the talk list. A quick brief of the case can be found here.\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#mapping-with-image",
    "href": "presentations/index.html#mapping-with-image",
    "title": "Presentations",
    "section": "Mapping with Image",
    "text": "Mapping with Image\n\n\n\n\n\n\n\n\nPechaKucha @ Senseable City Lab 2023\n\n\n\nDate: Jul 26, 2023  Location: School of Architecture and Planning, Massachusetts Institute of Technology\nA brief of my previous research and work. Due to the time limit, mostly is about urban imagery analysis. It is the application for the research work at Senseable City Lab. The process was smooth and successful.\n\n\n\n\n\nSlides Here\n\n\n\n\n\n\n\n\n\n\nGuest Talk @ Zhengzhou International Urban Design Conference 2019\n\n\n\nDate: Oct 17, 2019  Location: Zhengzhou, China\n\n\n\n\n\nSlides Here\n\n\n\n\n\n\n\n\n\n\nGuest Talk @ ESCAP, UN 2019\n\n\n\nDate: Jul 25, 2019  Location: Jakarta, Indonesia\nMy team is invited as a representative of FCIC to participate in the project initiation meeting on “Improving the Use and Sharing of Geospatial Information to Promote Resilient and Sustainable Development.” This event, hosted by the United Nations Economic and Social Commission for Asia and the Pacific (UN-ESCAP) and organized by the Indonesian National Institute of Aeronautics and Space (LAPAN). During this meeting, we engaged in vibrant discussions with representatives from Cambodia, Mongolia, Thailand, Kyrgyzstan, Indonesia, and experts from research institutions such as The Chinese University of Hong Kong, the Remote Sensing Institute of the Chinese Academy of Sciences, and the City University of Macau.\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#experience-with-urban-data",
    "href": "presentations/index.html#experience-with-urban-data",
    "title": "Presentations",
    "section": "Experience with urban data",
    "text": "Experience with urban data\n\n\n\n\n\n\n\n\nLunch Talk @ City Form Lab\n\n\n\nDate: Oct 12, 2022  Location: School of Architecture and Planning, Massachusetts Institute of Technology\nA brief of my previous research and work. It’s a 45-min talk, the talk includes my previous data-driven research and practice. The audience are all City Form Lab members.\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#seeing-city",
    "href": "presentations/index.html#seeing-city",
    "title": "Presentations",
    "section": "Seeing City",
    "text": "Seeing City\n\n\n\n\n\n\n\n\nGuest Talk @ World Bank 2019\n\n\n\nDate: May 14, 2019  Location: World Bank Beijing Office\nIt’s an 30 mins talk about recent projects from CitoryTech team. The talk covered a series of urban data research, practice in our exploration of understanding our city with images.\n\n\n\n\n\nSlides Here\n\n\n\n\n\n\n\n\n\n\nGuest Lecture @ HKU 2019\n\n\n\nDate: Mar 11, 2019  Location: Faculty of Architecture, Hong Kong University\nIt’s an 1-hour talk about recent projects from CitoryTech team. The talk covered a series of urban data research, practice in our exploration of understanding our city with images. I also introduced the development of crowd sourcing tools.\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#streetalk-pitch",
    "href": "presentations/index.html#streetalk-pitch",
    "title": "Presentations",
    "section": "StreeTalk Pitch",
    "text": "StreeTalk Pitch\n\n\n\n\n\n\n\n\nPresentation @ SODA 2017\n\n\n\nDate: Nov, 2017  Location: Shanghai\nThis is a 10-minute business plan presentation for our original project, StreeTalk. We were honored to receive the seed award and seed funding for CitoryTech.\nAdditionally, this project played a pivotal role in securing our first order from Daimler, through which we sold our safety maps, encompassing over 300 cities in China.\n\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#national-population-flow-analysis-based-on-1-billion-lbsn-data",
    "href": "presentations/index.html#national-population-flow-analysis-based-on-1-billion-lbsn-data",
    "title": "Presentations",
    "section": "National Population Flow Analysis Based on 1 billion LBSN data",
    "text": "National Population Flow Analysis Based on 1 billion LBSN data\n\n\n\n\n\n\n\n\nKeynote Speech @ China Urban Planning Annual Conference 2016\n\n\n\nDate: Sep 26, 2016  Location: Shenyang\nA presentation on the study of national population movements, utilizing the Tencent LBSN dataset, was delivered. For the first time, it showcased an analysis of urban clusters and the regional framework across the whole country.\nA brief of the project can be found here.\n\n\n\n\nSlides Here"
  },
  {
    "objectID": "presentations/index.html#gtfs-and-afc-data-analysis",
    "href": "presentations/index.html#gtfs-and-afc-data-analysis",
    "title": "Presentations",
    "section": "GTFS and AFC Data Analysis",
    "text": "GTFS and AFC Data Analysis\n\n\n\n\n\n\n\n\nPresentation @ MTA 2013\n\n\n\nDate: Aug, 2013  Location: New York\nThis is a 30-minute presentation\n\n\n\n\n\nSlides Here"
  }
]